---
title: "Advanced Modeling Options"
author: "Julia Haaf & Stephen Rhodes"
output:
  ioslides_presentation:
    logo: pictures/MUlogoRGB.png
    widescreen: true
---

```{r setup, echo = F, warning=FALSE}
# MLE Rouder et al (2008) PNAS
cd = read.table(file = "data/rouder08-data-0.5.dat")

# the data frame gives numbers of hits, misses, false-alarms, and correct rejections
# for three set sizes: N = 2,5,8
N = c(2,5,8)
N_i = rep(1:length(N), each=4) # index

#Multinomial Negative Log-Likelihood
negLL <- function(y,p){
  a=ifelse(y==0 & p==0,0, y*log(p))
  -sum(a)
}

cowan_k <- function(k, a, g, N){
  d = min(1,k/N) # p(probe in memory)
  p = 1:4
  p[1] = a*(d+(1-d)*g)+(1-a)*g # p(hit)
  p[2] = 1-p[1] # p(miss)
  p[3] = a*(1-d)*g+(1-a)*g # p(false-alarm)
  p[4] = 1-p[3] # p(correct rejection)
  return(p)
}

sdt <- function(d, c, s){
  # this is a simplified version of the sdt 
  # model used by rouder et al.
  p = 1:4
  p[1] = pnorm((d - c)/s) # p(hit)
  p[2] = 1 - p[1] # p(miss)
  p[3] = pnorm(- c) # p(false-alarm)
  p[4] = 1 - p[3] # p(correct rejection)
  return(p)
}

# Likelihood functions

## Binomial Model
ll.vacuous <- function(y){
  ll = 0
  lenY = length(y)
  y1 = y[rep(c(T, F), lenY/2)]
  y2 = y[rep(c(F, T), lenY/2)]
  n = (rep((y1+y2), each=2))
  p = y/n
  ll = negLL(y, p)
  return(ll)
}

## Fixed Capacity Model
ll.fixed_k <- function(par, y){
  # length(par) == 3 (k, a, g)
  ll = 0
  for(i in 1:length(N)){ # for each set size
    p = cowan_k(k = par[1], a = par[2], g = par[3], N = N[i])
    ll = ll + negLL(y[N_i==i], p)
  }
  if(any(c(par < rep(0,3), par > c(max(N),1,1)))){
    ll = ll + 10000 # penalty for going out of range
  }
  return(ll)
}

## Varying Capacity Model
ll.vary_k <- function(par, y){
  # length(par) == 5 (k*3, a, g)
  ll=0
  for(i in 1:length(N)){ # for each set size
    p = cowan_k(k = par[i], a = par[4], g = par[5], N = N[i])
    ll = ll + negLL(y[N_i==i], p)
  }
  if(any(c(par < rep(0,5), par > c(rep(max(N), 3),1,1)))){
    ll = ll + 10000 # penalty for going out of range
  }
  return(ll)
}

## Equal-Variance Signal Detection Model
ll.sdt.ev <- function(par, y){
  # length(par) == 4 (d1, d2, d3, c)
  ll=0
  for(i in 1:length(N)){ # for each set size
    p = sdt(d = par[i], c = par[length(N)+1], s = 1)
    ll = ll + negLL(y[N_i==i], p)
  }
  return(ll)
}

# function to calculate fit statistics from -LL
fit_stats <- function(nLL, n, p){
  # nLL = negative log liklihood
  # n = number of observations
  # p = number of parameters
  
  deviance = 2*nLL
  aic = deviance + 2*p
  bic = deviance + p*log(n)
  
  return(list("D" = deviance, "AIC" = aic, "BIC" = bic))
}
#### FIT TO INDIVIDUALS ----

S = nrow(cd) # number of participants

# create matrices to hold the resulting parameter estimates
# 1 row per participant, 1 column per parameter
estimates_fix_k <- matrix(NA, nrow = S, ncol = 3)
colnames(estimates_fix_k) <- c("k", "a", "g")

estimates_vary_k <- matrix(NA, nrow = S, ncol = 5)
colnames(estimates_vary_k) <- c("k1", "k2", "k3", "a", "g")

estimates_sdt <- matrix(NA, nrow = S, ncol = 4)
colnames(estimates_sdt) <- c("d1", "d2", "d3", "c")

# create a matrix to hold the -log likelihood for each individual (row)
# and each model (col)
fit_statistics <- matrix(NA, nrow = S, ncol = 5)
colnames(fit_statistics) <- c("LL_vac", "LL_fix_k", "LL_vary_k", "LL_sdt", "N_obs")

# this loop takes the data from each row (participant) and fits the three models
for (s in 1:S){
  # get the data for this subject
  tmp.dat = as.integer(cd[s,])

  # model that freely estimates response frequencies
  fit_statistics[s,1] <- ll.vacuous(y = tmp.dat)
  
  # fixed k
  par = runif(n = 3, min = 0, max = c(max(N), 1, 1))
  k_res_s = optim(par, ll.fixed_k, y = tmp.dat)
  
  fit_statistics[s,2] <- k_res_s$value # add estimates and LL to matrices
  estimates_fix_k[s,] <- k_res_s$par
  
  # variable k
  par = runif(n = 5, min = 0, max = c(rep(max(N),3), 1, 1))
  vary_k_res_s = optim(par, ll.vary_k, y = tmp.dat)
  
  fit_statistics[s,3] <- vary_k_res_s$value
  estimates_vary_k[s,] <- vary_k_res_s$par
  
  ## sdt model
  par = runif(n = 4, min = 0, max = c(5, 5, 5, 5))
  sdt_res_s = optim(par, ll.sdt.ev, y = tmp.dat)
  
  fit_statistics[s,4] <- sdt_res_s$value
  estimates_sdt[s,] <- sdt_res_s$par
  
  fit_statistics[s,5] = sum(tmp.dat)
}
# remove stuff we no longer need...
rm(list = c("tmp.dat", "k_res_s", "vary_k_res_s", "sdt_res_s"))
```

## Good To Know

- Advanced models
    - General high-threshold model
    - Unequal-variance signal detection model
- Model comparison with "unrelated" models
    - AIC
    - BIC
- Problems & Fixes: Null counts

# Advanced Models

## General High-Threshold Model (GHT)

Extension of the double-high-threshold model

```{r twohtmodelb,engine='tikz',fig.ext='svg',fig.width=7, echo = F, fig.align='center'}
\begin{tikzpicture}[level 1/.style={sibling distance=4cm}, level 2/.style={sibling distance=3cm}, grow=right, yscale=-1, xscale=1.4]

% target tree
\node [rectangle, draw] (a) {Signal}
  child {node [rectangle, draw] (b) {Detect Signal} % detect
    child {node [rectangle, draw] (c) [anchor=west] {hit}}}
  child {node [rectangle, draw] (d) {Fail to Detect} % not detect
    child {node [rectangle, draw] (e) [anchor=west] {hit}}
    child {node [rectangle, draw] (f) [anchor=west] {miss}}};
% non-target tree    
\node [rectangle, draw] (g) [right =6.5cm] {Noise}
  child {node [rectangle, draw] (h) {Detect Noise} % detect
    child {node [rectangle, draw] (i) [anchor=west] {correct rejection}}}
  child {node [rectangle, draw] (j) {Fail to Detect} % not detect
    child {node [rectangle, draw] (k) [anchor=west] {false alarm}}
    child {node [rectangle, draw] (l) [anchor=west] {correct rejection}}};
% add lines and labels
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$d$} (b);
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$1 - d$} (d);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$g$} (e);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$1 - g$} (f);
\draw[->,>=stealth] (b) -- (c);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$d$} (h);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$1 - d$} (j);
\draw[->,>=stealth] (j) -- node[midway,fill=white] {$g$} (k);
\draw[->,>=stealth] (j) -- node[midway,fill=white] {$1 - g$} (l);
\draw[->,>=stealth] (h) -- (i);

\end{tikzpicture}
```

## General High-Threshold Model

```{r ghtmodelb,engine='tikz',fig.ext='svg',fig.width=7, echo = F, fig.align='center'}
\begin{tikzpicture}[level 1/.style={sibling distance=4cm}, level 2/.style={sibling distance=3cm}, grow=right, yscale=-1, xscale=1.4]

% target tree
\node [rectangle, draw] (a) {Signal}
  child {node [rectangle, draw] (b) {Detect Signal} % detect
    child {node [rectangle, draw] (c) [anchor=west] {hit}}}
  child {node [rectangle, draw] (d) {Fail to Detect} % not detect
    child {node [rectangle, draw] (e) [anchor=west] {hit}}
    child {node [rectangle, draw] (f) [anchor=west] {miss}}};
% non-target tree    
\node [rectangle, draw] (g) [right =6.5cm] {Noise}
  child {node [rectangle, draw] (h) {Detect Noise} % detect
    child {node [rectangle, draw] (i) [anchor=west] {correct rejection}}}
  child {node [rectangle, draw] (j) {Fail to Detect} % not detect
    child {node [rectangle, draw] (k) [anchor=west] {false alarm}}
    child {node [rectangle, draw] (l) [anchor=west] {correct rejection}}};
% add lines and labels
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$\mathbf{d_s}$} (b);
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$1 - \mathbf{d_s}$} (d);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$g$} (e);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$1 - g$} (f);
\draw[->,>=stealth] (b) -- (c);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$\mathbf{d_n}$} (h);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$1 - \mathbf{d_n}$} (j);
\draw[->,>=stealth] (j) -- node[midway,fill=white] {$g$} (k);
\draw[->,>=stealth] (j) -- node[midway,fill=white] {$1 - g$} (l);
\draw[->,>=stealth] (h) -- (i);

\end{tikzpicture}
```

## General High-Threshold Model

Let's go back to the change-detection example. How would we fit a general high-threshold version of the fixed-capacity model?

>- Does it even make sense?
>- Here, $d = k/n$
>- Does it make sense that there are separate capacities for items in memory and items *not* in memory?
>- Identifiability issues

```{r, echo = F, message=F, warning=F}
group_data = apply(cd, 2, sum)
# starting values
par = runif(n = 5, min = 0, max = c(rep(max(N),3), 1, 1))
vary_k_res = optim(par, ll.vary_k, y = group_data)

parameter.estimates <- vary_k_res$par
names(parameter.estimates) <- c("k2", "k5", "k8", "a", "g")
```

## Unequal Variance Signal Detection Model (UVSD)

Equal variance: 

```{r echo = F}
x <- seq(-3, 5, .01)
y.noise <- dnorm(x)
y.signal <- dnorm(x, 1.5)

plot(x, y.noise
     , type = "l", lwd = 2
     , xlim = range(x)
     , frame.plot = F
     , ylab = "Density"
     , xlab = "Sensory Strength"
     )
lines(x, y.signal, col = "firebrick4", lwd = 2)
# make.line(0)
# make.line(1.5, 1.5)
abline(v = 1, lwd = 2, col = "darkgreen")
axis(3, at = c(0, 1.5), labels = c("", ""))
mtext("d'", 3, line = .5, at = .75, cex = 1.3)
text(1.2, .03, "c", cex = 1.3)
text(-2, .25, "Stimulus absent")
text(3.5, .25, "Stimulus present")
```

## Unequal Variance Signal Detection Model (UVSD)

Let mean *and* variance vary for signal distribution!

```{r echo = F}
x <- seq(-3, 5, .01)
y.noise <- dnorm(x)
y.signal <- dnorm(x, 1.5, 1.5)

plot(x, y.noise
     , type = "l", lwd = 2
     , xlim = range(x)
     , frame.plot = F
     , ylab = "Density"
     , xlab = "Sensory Strength"
     )
lines(x, y.signal, col = "firebrick4", lwd = 2)
# make.line(0)
# make.line(1.5, 1.5)
abline(v = 1, lwd = 2, col = "darkgreen")
axis(3, at = c(0, 1.5), labels = c("", ""))
mtext("d'", 3, line = .5, at = .75, cex = 1.3)
text(1.2, .03, "c", cex = 1.3)
text(-2, .25, "Stimulus absent")
text(3.5, .25, "Stimulus present")
```
## UVSD for change detection

```{r, echo = F}

par(mar=c(4,3,1,1))
curve(expr = dnorm(x, 0, 1), from = -3, to = 6, xlab="Strength of evidence for 'change'", ylab="", lwd=2)

curve(expr = dnorm(x, 1, 1.2), col="tomato", from = -3, to = 6, lwd=2, add = T)
curve(expr = dnorm(x, 2, 1.2), col="forestgreen", from = -3, to = 6, lwd=2, add = T)
curve(expr = dnorm(x, 3, 1.2), col="dodgerblue", from = -3, to = 6, lwd=2, add = T)

legend("topleft", legend = c(2,5,8), lty = 1, col = c("dodgerblue", "forestgreen","tomato"), title = "N", lwd=2, bty='n')

```

## Even more UVSD for change detection

```{r echo = F}

par(mar=c(4,3,1,1))
curve(expr = dnorm(x, 0, 1), from = -3, to = 6, xlab="Strength of evidence for 'change'", ylab="", lwd=2)

curve(expr = dnorm(x, 1, 1.5), col="tomato", from = -3, to = 6, lwd=2, add = T)
curve(expr = dnorm(x, 2, 1.2), col="forestgreen", from = -3, to = 6, lwd=2, add = T)
curve(expr = dnorm(x, 3, 2), col="dodgerblue", from = -3, to = 6, lwd=2, add = T)

legend("topleft", legend = c(2,5,8), lty = 1, col = c("dodgerblue", "forestgreen","tomato"), title = "N", lwd=2, bty='n')

```

## Unequal Variance Signal Detection Model (UVSD)

Downside:

>- This is an extremely flexible mode
>- Can fit nearly all data patterns
>- Not that many parameters
>- Often preferred in frequentist model comparison
>- Interpretation difficult

## Unequal Variance Signal Detection Model (UVSD)

```{r}
## Unequal-Variance Signal Detection Model
ll.sdt.uv <- function(par, y){
  # length(par) == 7 (d1, d2, d3, c, s1, s2, s3)
  ll=0
  for(i in 1:length(N)){ # for each set size
    p = sdt(d = par[i], c = par[length(N) + 1], s = par[length(N) + 1 + i])
    ll = ll + negLL(y[N_i==i], p)
  }
  if(any(par[5:7] < rep(0,3))){
    ll = ll + 10000} # penalty for going out of range
  return(ll)
}
```

## Unequal Variance Signal Detection Model (UVSD) {.smaller}

```{r}
## fit uvsd model
par = runif(n = 7, min = .1, max = 3)
sdt_res_uv = optim(par, ll.sdt.uv, y = group_data)
sdt_res_uv$par

## fit evsd model
par = runif(n = 4, min = .1, max = 3)
sdt_res = optim(par, ll.sdt.ev, y = group_data)
sdt_res$par

c(sdt_res_uv$value, sdt_res$value)
```

# Model comparison

## Model comparison with "unrelated" models

>- $\chi^2$-test with $G^2 = 2(LL_g - LL_r)$ only works with nested models
>- We can compare UVSD to EVSD, or Varying Capacity to Fixed Capacity
>- We cannot compare EVSD to Fixed Capacity with the $G^2$-test
>- Needed: Test statistic that rewards low likelihood values and punishes complexity
>- AIC and BIC

##Akaike information criterion (AIC)

\[AIC = - 2 \log(L) + 2 p,\]

where $m$ is the number of parameters and $- 2 \log(L)$ is two times the negative log likelihood.

##Bayesian information criterion (BIC)

\[AIC = - 2 \log(L) + 2 p,\]

where $p$ is the number of parameters and $- 2 \log(L)$ is two times the negative log likelihood.

\[BIC = - 2 \log(L) +  p \log(n),\]

where $n$ is the number of observations.

*Q:* Do you want higher or lower values of AIC/BIC?

## AIC and BIC in R

```{r}
# function to calculate fit statistics from -LL
fit_stats <- function(nLL, n, p){
  # nLL = negative log liklihood
  # n = number of observations
  # p = number of parameters
  
  deviance = 2*nLL
  aic = deviance + 2*p
  bic = deviance + p*log(n)
  
  return(list("D" = deviance, "AIC" = aic, "BIC" = bic))
}
```

## AIC and BIC in R

```{r, echo = F, warning = F}
## fit k model
# starting values
par = runif(n = 3, min = 0, max = c(max(N), 1, 1))
k_res = optim(par, ll.fixed_k, y = group_data)

# starting values
par = runif(n = 5, min = 0, max = c(rep(max(N),3), 1, 1))
vary_k_res = optim(par, ll.vary_k, y = group_data)

## fit sdt model
par = runif(n = 4, min = 0, max = c(5, 5, 5, 5))
sdt_res = optim(par, ll.sdt.ev, y = group_data)
```


```{r}
sdt_fit = fit_stats(nLL = sdt_res$value, n = sum(group_data), p = 4)
k_fit = fit_stats(nLL = k_res$value, n = sum(group_data), p = 3)
vary_k_fit = fit_stats(nLL = vary_k_res$value, n = sum(group_data), p = 5)

c(sdt_fit$AIC, k_fit$AIC, vary_k_fit$AIC)

c(sdt_fit$BIC, k_fit$BIC, vary_k_fit$BIC)
```

## AIC and BIC in R

```{r}
sdt_fit = fit_stats(nLL = sdt_res$value, n = sum(group_data), p = 4)
k_fit = fit_stats(nLL = k_res$value, n = sum(group_data), p = 3)
vary_k_fit = fit_stats(nLL = vary_k_res$value, n = sum(group_data), p = 5)

c(sdt_fit$AIC, k_fit$AIC, vary_k_fit$AIC)

c(sdt_fit$BIC, k_fit$BIC, vary_k_fit$BIC)
```

Remember: The lower the better

## AIC and BIC

>- Can also be used to compare model fit for all individuals independently
>- A landscape of information criterial
>- s (participants) x m (models) AIC or BIC
>- Who is fit best by model m?
>- Which model fits participant s' data best?
>- Go to `mle-rouder08-indiv.R`

## AIC and BIC for individuals

1.  Fit models to all individuals using a `for()`-loop
2.  Extract negative log likelihood value and calculate AIC/BIC
3.  Summarize in a table
4.  Which mode is preferred for which participant?



# Problems & Fixes: Null counts

## Null counts

>- Occasional absence of either miss or false-alarm event
>- Especially problematic for SDT
>- Especially problematic when fitting models to individuals' data

## Null counts {.build}

There is an easy fix:

\[
\hat{p}_h = \frac{y_h + .5}{N_s + 1}, \\
\hat{p}_f = \frac{y_f + .5}{N_f + 1}.
\]

This is done by adding $+.5$ to each observed cell count

## Null counts

This is done by adding $+.5$ to each observed cell count

```{r, eval = F}
# this loop takes the data from each row (participant) and fits the three models
for (s in 1:S){
  # get the data for this subject
  tmp.dat = as.integer(cd[s,]) + .5
  
  # model that freely estimates response frequencies
  fit_statistics[s,1] <- ll.vacuous(y = tmp.dat)
  
  ...
```

You can find the code at the end of `mle-rouder08-indiv.R`
