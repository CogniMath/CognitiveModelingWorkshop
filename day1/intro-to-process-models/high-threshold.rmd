---
title: "High-Threshold Models"
author: "Julia Haaf & Stephen Rhodes"
output:
  ioslides_presentation:
    logo: pictures/MUlogoRGB.png
    widescreen: true
subtitle: A pragmatic introduction 
---

# Signal Detection Experiment

## Signal Detection Experiment | Example

>- Subliminal perception
>- Very brief presentation of a word vs. no word
>- Signal: + ... TRUMP ... *****
>- Noise: + ... &emsp; &emsp; &emsp; ... *****

## Signal Detection Experiment | Example

**Results**

| Stimulus | Present response | Absent Response | Total | 
|:------|:-----:|:---------:|:------:| 
|   Signal  |  75  |    25   |    100  | 
|  Noise  |  30 |   20   |   50  | 
|  Total  |  105 |   45   |     | 

>- Hits, Misses, False Alarms, Correct Rejections
>- vs. Accuracy

## Modeling a Signal Detection Experiment

>- Let $Y_h$, $Y_m$, $Y_f$, and $Y_c$ be random variables denoting counts of events
>- $N_s$ and $N_n$ denote numbers of signal and noise trials
>- How many independent pieces of data?

>- Simple binomial model:
\[
Y_h \sim \mbox{Binomial}(N_s, p_h),\\
Y_f \sim \mbox{Binomial}(N_n, p_f).
\]

>- Maximum-Likelihood estimates here are $\hat{p}_h = \frac{y_h}{N_s} = 75/100 = .75$ and $\hat{p}_f = \frac{y_f}{N_n} = 30/50 = .6$
>- Any concerns with this model?

## High-Threshold Model 

Perception as an all-or-none process

```{r htmodel,engine='tikz',fig.ext='svg',fig.width=8, echo = F, fig.align='center'}
\begin{tikzpicture}[level 1/.style={sibling distance=4cm}, level 2/.style={sibling distance=3cm}, grow=right, yscale=-1, xscale=1.5]

% target tree
\node [rectangle, draw] (a) {Signal}
  child {node [rectangle, draw] (b) {Detect Signal} % detect
    child {node [rectangle, draw] (c) [anchor=west] {hit}}}
  child {node [rectangle, draw] (d) {Fail to Detect} % not detect
    child {node [rectangle, draw] (e) [anchor=west] {hit}}
    child {node [rectangle, draw] (f) [anchor=west] {miss}}};
% non-target tree    
\node [rectangle, draw] (g) [right =7cm] {Noise}
  child {node [rectangle, draw] (h) {false alarm}}
  child {node [rectangle, draw] (i) {correct rejection}};
% add lines and labels
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$d$} (b);
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$1 - d$} (d);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$g$} (e);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$1 - g$} (f);
\draw[->,>=stealth] (b) -- (c);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$g$} (h);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$1 - g$} (i);

\end{tikzpicture}
```

##HTM as Statistical Model

>- Simple binomial model:
\[
Y_h \sim \mbox{Binomial}(N_s, p_h),\\
Y_f \sim \mbox{Binomial}(N_n, p_f).
\]
>- High-Threshold model:
\[
Y_h \sim \mbox{Binomial}(N_s, d + (1 - d)g),\\
Y_f \sim \mbox{Binomial}(N_n, g).
\]

```{r,engine='tikz',fig.ext='svg',fig.width=4, echo = F, fig.align='right'}
\begin{tikzpicture}[level 1/.style={sibling distance=4cm}, level 2/.style={sibling distance=3cm}, grow=right, yscale=-1, xscale=1.5]

% target tree
\node [rectangle, draw] (a) {Signal}
  child {node [rectangle, draw] (b) {Detect Signal} % detect
    child {node [rectangle, draw] (c) [anchor=west] {hit}}}
  child {node [rectangle, draw] (d) {Fail to Detect} % not detect
    child {node [rectangle, draw] (e) [anchor=west] {hit}}
    child {node [rectangle, draw] (f) [anchor=west] {miss}}};
% non-target tree    
\node [rectangle, draw] (g) [right =7cm] {Noise}
  child {node [rectangle, draw] (h) {false alarm}}
  child {node [rectangle, draw] (i) {correct rejection}};
% add lines and labels
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$d$} (b);
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$1 - d$} (d);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$g$} (e);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$1 - g$} (f);
\draw[->,>=stealth] (b) -- (c);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$g$} (h);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$1 - g$} (i);

\end{tikzpicture}
```

##HTM as Statistical Model | Estimates

- High-Threshold model:
\[
Y_h \sim \mbox{Binomial}(N_s, d + (1 - d)g),\\
Y_f \sim \mbox{Binomial}(N_n, g).
\]
- Maximum likelihood estimates for this model can be directly derived
- $\hat{d} = \frac{\hat{p}_h - \hat{p}_f}{1 - \hat{p}_f} = .375$
- $\hat{g} = \hat{p}_f = .6$

##HTM in R

Now we need our function-writing skills!

```{r}
#negative log likelihood of high-threshold model
nll.ht <- function(par, y){ #1. argument: vector with parameters, 2. arg: vector with data (h, m, f, c)
  d <- par[1]
  g <- par[2]
  p <- 1:4 # reserve space
  p[1] <- d + (1 - d) * g   #probability of a hit
  p[2] <- 1 - p[1]          # probability of a miss
  p[3] <- g                 # probability of a false alarm
  p[4] <- 1 - p[3]          #probability of a correct rejection
  return(-sum(y * log(p)))
}
```

##HTM in R | Data analysis

Maximize the function

```{r}
y <- c(75, 25, 30, 20) #h, m, f, c
par <- c(.5, .5) #starting values for probability parameters
out <- optim(par, nll.ht, y = y)
print(out$par)
```

>- Compare to analytic solution: $\hat{d} = .375$ and $\hat{g} = .6$

# Testing for Selective Influence

## Is Perception All-or-none?

>- How can we test this experimentally for subliminal perception?
>- Manipulations affecting the guessing parameter $g$, e.g. reward manipulation
>- Manipulations affecting the strength parameter $d$, e.g. presentation time manipulation (12ms vs. 20ms)
>- How would you test selective influence with a high-threshold model?

## Model Extension

Let $i$ denote condition, $i = 1$ for 12ms presentation and $i = 2$ for 20ms presentation.

```{r,engine='tikz',fig.ext='svg',fig.width=8, echo = F, fig.align='center'}
\begin{tikzpicture}[level 1/.style={sibling distance=4cm}, level 2/.style={sibling distance=3cm}, grow=right, yscale=-1, xscale=1.5]

% target tree
\node [rectangle, draw] (a) {Signal}
  child {node [rectangle, draw] (b) {Detect Signal} % detect
    child {node [rectangle, draw] (c) [anchor=west] {hit}}}
  child {node [rectangle, draw] (d) {Fail to Detect} % not detect
    child {node [rectangle, draw] (e) [anchor=west] {hit}}
    child {node [rectangle, draw] (f) [anchor=west] {miss}}};
% non-target tree    
\node [rectangle, draw] (g) [right =7cm] {Noise}
  child {node [rectangle, draw] (h) {false alarm}}
  child {node [rectangle, draw] (i) {correct rejection}};
% add lines and labels
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$d_i$} (b);
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$1 - d_i$} (d);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$g_i$} (e);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$1 - g_i$} (f);
\draw[->,>=stealth] (b) -- (c);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$g_i$} (h);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$1 - g_i$} (i);

\end{tikzpicture}
```

## Model Extension

In model notation:
\[
Y_{ih} \sim \mbox{Binomial}(N_{is}, d_i + (1 - d_i)g_i),\\
Y_{if} \sim \mbox{Binomial}(N_{in}, g_i).
\]

## Model Comparison

**General Model**
\[
Y_{ih} \sim \mbox{Binomial}(N_{is}, d_i + (1 - d_i)g_i),\\
Y_{if} \sim \mbox{Binomial}(N_{in}, g_i).
\]

>- Selective influence can be tested by gradually restricting this model
>- $M_1$: Restricting $d_1 = d_2$
>- $M_2$: Restricting $g_1 = g_2$
>- Model comparison by comparing the fit of the models to the data (same as regression)

## Model Comparison

**General Model**
\[
Y_{ih} \sim \mbox{Binomial}(N_{is}, d_i + (1 - d_i)g_i),\\
Y_{if} \sim \mbox{Binomial}(N_{in}, g_i).
\]

**Model 1**
\[
Y_{ih} \sim \mbox{Binomial}(N_{is}, d + (1 - d)g_i),\\
Y_{if} \sim \mbox{Binomial}(N_{in}, g_i).
\]

**Model 2**
\[
Y_{ih} \sim \mbox{Binomial}(N_{is}, d_i + (1 - d_i)g),\\
Y_{if} \sim \mbox{Binomial}(N_{in}, g).
\]

## Models in R

```{r}
#negative log likelihood for any one condition
nll.condition <- function(par, y){ #assign par=c(d, g), y = c(h, m, f, c)
p <- 1:4
d <- par[1]
g <- par[2]
p[1] <- d + (1 - d) * g
p[2] <- 1 - p[1]
p[3] <- g
p[4] <- 1 - p[3]
return(-sum(y * log(p)))
}
```

## Models in R {.smaller}

```{r}
#negative log likelihood for General Model:
#assign par4 = (d1, g1, d2, g2), y8 = (h1, m1, f1, c1, h2, m2, f2, c2)
nll.g <- function(par4, y8){            
nll.condition(par4[1:2], y8[1:4]) +     #condition 1
nll.condition(par4[3:4], y8[5:8])       #condition 2
}

#negative log likelihood for Model 1:
#assign par3 = (d, g1, g2), y8 = (h1, m1, f1, c1, h2, m2, f2, c2)
nll.1 <- function(par3, y8){            
nll.condition(par3[1:2], y8[1:4]) +     #condition 1
nll.condition(par3[c(1, 3)], y8[5:8])       #condition 2
}

#negative log likelihood for Model 2:
#assign par3 = (d1, d2, g), y8 = (h1, m1, f1, c1, h2, m2, f2, c2)
nll.2 <- function(par3, y8){            
nll.condition(par3[c(1, 3)], y8[1:4]) +     #condition 1
nll.condition(par3[2:3], y8[5:8])       #condition 2
}
```

## Data and Analysis

```{r}
dat <- c(22, 28, 22, 28   #h, m, f, c for condition 1
         , 35, 15, 21, 29) #h, m, f, c for condition 2

#General Model
par.m <- c(.5, .5, .5, .5) #starting values
mod.g  <- optim(par.m, nll.g,y8 = dat, hessian = T)

#Model 1
par.m <- c(.5, .5, .5) #starting values
mod.1 <- optim(par.m, nll.1, y8 = dat, hessian = T)

#Model 2
par.m <- c(.5, .5, .5) #starting values
mod.2 <- optim(par.m, nll.2, y8 = dat, hessian = T)
```

## Estimation Results

```{r, echo = F}
output.par <- matrix(c(round(mod.g$par, 3), "", ""
                       , "", round(mod.1$par[2], 3), "", round(mod.1$par[c(3, 1)], 3), ""
                       , round(mod.2$par[1], 3), "", round(mod.2$par[2], 3), "", "", round(mod.2$par[3], 3))
                     , ncol = 6, byrow = T)
rownames(output.par) <- c("General Model", "Model 1", "Model 2")
colnames(output.par) <- c("d1", "g1", "d2", "g1", "d", "g")

library("knitr")
kable(output.par)
```

## Model Comparison

Let's take a look at the maximum likelihood value
```{r}
c(mod.g$value, mod.1$value, mod.2$value)
```

## Model Comparison

And calculate the $G^2$-statistic.
```{r}
G1 <- 2*(mod.1$value - mod.g$value)
G2 <- 2*(mod.2$value - mod.g$value)
```

Under the Null, $G^2$ follows a $\chi^2$-distribution with 1 degree of freedom (one parameter less).
```{r}
qchisq(.95, df = 1) #Critical value for alpha = .05

c(m1 = 1 - pchisq(G1, df = 1), m2 = 1 - pchisq(G2, df = 1)) #p-values
```

## Trial & Error

You are testing the validity of the high-threshold model for the perception of faint audio tones with a selective influence test.  In Condition 1, you pay 10c for each hit and 1c for each correct rejection. In Condition 2, you pay the reverse (1c for each hit and 10c for each correct rejection). Condition
1 favors tone-present responses; condition 2 favors a tone-absent responses. **The manipulation is hypothesized to affect $g$ and not $d$.** The obtained data are given below. Use `R` to test for selective influence.

```{r, echo = F}
newdat <- matrix(c(40, 10, 30, 20
                   , 15, 35, 2, 48)
                     , ncol = 4, byrow = T)
rownames(newdat) <- c("Condition 1", "Condition 2")
colnames(newdat) <- c("Hit", "Miss", "False Alarm", "Correct Rejection")

library("knitr")
kable(newdat)
```

## Trial & Error: Solution | Fit Models to Data

```{r}
dat2 <- c(40, 10, 30, 20
          , 15, 35, 2, 48)

#General Model
par.m <- c(.5, .5, .5, .5) #starting values
mod.g  <- optim(par.m, nll.g, y8 = dat2, hessian = T)

#Model 1
par.m <- c(.5, .5, .5) #starting values
mod.1 <- optim(par.m, nll.1, y8 = dat2, hessian = T)

#Model 2
par.m <- c(.5, .5, .5) #starting values
mod.2 <- optim(par.m, nll.2, y8 = dat2, hessian = T)
```

## Trial & Error: Solution | Check Parameter Estimates

```{r, echo = F}
output.par <- matrix(c(round(mod.g$par, 3), "", ""
                       , "", round(mod.1$par[2], 3), "", round(mod.1$par[c(3, 1)], 3), ""
                       , round(mod.2$par[1], 3), "", round(mod.2$par[2], 3), "", "", round(mod.2$par[3], 3))
                     , ncol = 6, byrow = T)
rownames(output.par) <- c("General Model", "Model 1", "Model 2")
colnames(output.par) <- c("d1", "g1", "d2", "g1", "d", "g")

library("knitr")
kable(output.par)
```

## Trial & Error: Solution | Fix Model 2

```{r}
#negative log likelihood for Model 2:
#assign par3 = (d1, d2, g), y8 = (h1, m1, f1, c1, h2, m2, f2, c2)
nll.2 <- function(par2, y8){            
nll.condition(par2[c(1, 2)], y8[1:4]) +     #condition 1
nll.condition(c(0, par2[2]), y8[5:8])       #condition 2
}

#Model 2
par.m <- c(.5, .5) #starting values
mod.2 <- optim(par.m, nll.2, y8 = dat2, hessian = T)
```

## Trial & Error: Solution | Check Parameter Estimates Again

```{r, echo = F}
output.par <- matrix(c(round(mod.g$par, 3), "", ""
                       , "", round(mod.1$par[2], 3), "", round(mod.1$par[c(3, 1)], 3), ""
                       , round(mod.2$par[1], 3), "", 0, "", "", round(mod.2$par[2], 3))
                     , ncol = 6, byrow = T)
rownames(output.par) <- c("General Model", "Model 1", "Model 2")
colnames(output.par) <- c("d1", "g1", "d2", "g1", "d", "g")

library("knitr")
kable(output.par)
```

## Trial & Error: Solution | Model Comparison

Calculate the $G^2$-statistic.
```{r}
G1 <- 2*(mod.1$value - mod.g$value)
G2 <- 2*(mod.2$value - mod.g$value)

c(G1, G2)

c(m1 = round(1 - pchisq(G1, df = 1), 3), m2 = 1 - pchisq(G2, df = 1)) #p-values
```

## Double-High-Threshold Model

```{r twohtmodel,engine='tikz',fig.ext='svg',fig.width=9.5, echo = F, fig.align='center'}
\begin{tikzpicture}[level 1/.style={sibling distance=4cm}, level 2/.style={sibling distance=3cm}, grow=right, yscale=-1, xscale=1.4]

% target tree
\node [rectangle, draw] (a) {Signal}
  child {node [rectangle, draw] (b) {Detect Signal} % detect
    child {node [rectangle, draw] (c) [anchor=west] {hit}}}
  child {node [rectangle, draw] (d) {Fail to Detect} % not detect
    child {node [rectangle, draw] (e) [anchor=west] {hit}}
    child {node [rectangle, draw] (f) [anchor=west] {miss}}};
% non-target tree    
\node [rectangle, draw] (g) [right =6.5cm] {Noise}
  child {node [rectangle, draw] (h) {Detect Noise} % detect
    child {node [rectangle, draw] (i) [anchor=west] {correct rejection}}}
  child {node [rectangle, draw] (j) {Fail to Detect} % not detect
    child {node [rectangle, draw] (k) [anchor=west] {correct rejection}}
    child {node [rectangle, draw] (l) [anchor=west] {false alarm}}};
% add lines and labels
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$d$} (b);
\draw[->,>=stealth] (a) -- node[midway,fill=white] {$1 - d$} (d);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$g$} (e);
\draw[->,>=stealth] (d) -- node[midway,fill=white] {$1 - g$} (f);
\draw[->,>=stealth] (b) -- (c);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$d$} (h);
\draw[->,>=stealth] (g) -- node[midway,fill=white] {$1 - d$} (j);
\draw[->,>=stealth] (j) -- node[midway,fill=white] {$g$} (k);
\draw[->,>=stealth] (j) -- node[midway,fill=white] {$1 - g$} (l);
\draw[->,>=stealth] (h) -- (i);

\end{tikzpicture}
```
